{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.14 (default, Feb 15 2018, 20:22:28) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]\n"
     ]
    }
   ],
   "source": [
    "print sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pymatgen/__init__.py:87: UserWarning: \n",
      "Pymatgen will drop Py2k support from v2019.1.1. Pls consult the documentation\n",
      "at https://www.pymatgen.org for more details.\n",
      "  at https://www.pymatgen.org for more details.\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pymatgen as mg\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataload import load_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_features(DATA_DIR, with_ext=True, with_geo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'natoms', 'spacegroup',\n",
    "                      'alpha', 'beta', 'gamma',\n",
    "                      'ga', 'o_cnt', 'cellvol', 'o_fraction', 'avg_mass',\n",
    "                      'bandgap', 'E0'], axis=1)\n",
    "X_test = test.drop(['id', 'natoms', 'spacegroup',\n",
    "                    'alpha', 'beta', 'gamma',\n",
    "                    'ga', 'o_cnt', 'cellvol', 'o_fraction', 'avg_mass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use log1p of energies to correct for skew\n",
    "y_bg_train = train['bandgap']\n",
    "y_e0_train = np.log1p(train['E0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode spacegroup_natoms\n",
    "X_train = pd.concat([X_train.drop('spacegroup_natoms', axis=1),\n",
    "                    pd.get_dummies(X_train['spacegroup_natoms'])], axis=1)\n",
    "X_test = pd.concat([X_test.drop('spacegroup_natoms', axis=1),\n",
    "                    pd.get_dummies(X_test['spacegroup_natoms'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Sklearn Model with XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.05,      # Step size shrinkage used in update (Learning rate)\n",
    "         'reg_alpha': 0.01,          # L1 regularization term on weights\n",
    "         'n_estimators': 700,\n",
    "         'max_depth': 4,\n",
    "         'subsample': 1,\n",
    "         'colsample_bytree': 0.90,\n",
    "         'colsample_bylevel': 0.90,\n",
    "         'silent': True,\n",
    "         'random_state': 42,\n",
    "         'objective': 'reg:linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator pipeline\n",
    "est = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=50, random_state=42)),\n",
    "    ('xgbreg', XGBRegressor(**param)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=50, random_state=42,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample...     reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search for bandgap model\n",
    "t_md = [3]\n",
    "t_lr = [0.01, 0.02, 0.05, 0.10, 0.20]\n",
    "t_ne = range(100, 700, 50)\n",
    "gridsearch_bg_0 = GridSearchCV(est,\n",
    "                              {'xgbreg__max_depth': t_md,\n",
    "                               'xgbreg__learning_rate': t_lr,\n",
    "                               'xgbreg__n_estimators': t_ne,\n",
    "                              },\n",
    "                              cv=5,\n",
    "                              n_jobs=4,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              return_train_score=False,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=50, random_state=42,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample...     reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'xgbreg__n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650], 'xgbreg__max_depth': [3], 'xgbreg__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_bg_0.fit(X_train, y_bg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbreg__learning_rate': 0.05,\n",
       " 'xgbreg__max_depth': 3,\n",
       " 'xgbreg__n_estimators': 650}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_bg_0.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07324532184180609"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridsearch_bg_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best regularization\n",
    "t_ra = [0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "gridsearch_bg_1 = GridSearchCV(est,\n",
    "                              {'xgbreg__reg_alpha': t_ra,\n",
    "                              },\n",
    "                              cv=5,\n",
    "                              n_jobs=4,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              return_train_score=False,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:   38.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=50, random_state=42,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample...     reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'xgbreg__reg_alpha': [0.1, 0.05, 0.01, 0.005, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_bg_1.fit(X_train, y_bg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbreg__reg_alpha': 0.01}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_bg_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07324532184180609"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridsearch_bg_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search for formation energy model\n",
    "t_md = [4]\n",
    "t_lr = [0.01, 0.02, 0.05, 0.10, 0.20]\n",
    "t_ne = range(100, 750, 50)\n",
    "gridsearch_e0_0 = GridSearchCV(est,\n",
    "                              {'xgbreg__max_depth': t_md,\n",
    "                               'xgbreg__learning_rate': t_lr,\n",
    "                               'xgbreg__n_estimators': t_ne,\n",
    "                              },\n",
    "                              cv=5,\n",
    "                              n_jobs=4,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              return_train_score=False,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 65 candidates, totalling 325 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=4)]: Done 325 out of 325 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=50, random_state=42,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample...     reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'xgbreg__n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700], 'xgbreg__max_depth': [4], 'xgbreg__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_e0_0.fit(X_train, y_e0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbreg__learning_rate': 0.05,\n",
       " 'xgbreg__max_depth': 4,\n",
       " 'xgbreg__n_estimators': 700}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_e0_0.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012683950744505168"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridsearch_e0_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best regularization\n",
    "t_ra = [0.2, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "gridsearch_e0_1 = GridSearchCV(est,\n",
    "                              {'xgbreg__reg_alpha': t_ra,\n",
    "                              },\n",
    "                              cv=5,\n",
    "                              n_jobs=4,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              return_train_score=False,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=50, random_state=42,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample...     reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'xgbreg__reg_alpha': [0.2, 0.1, 0.05, 0.01, 0.005, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_e0_1.fit(X_train, y_e0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbreg__reg_alpha': 0.05}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_e0_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012405782454539018"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridsearch_e0_1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models using optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_bg = {'learning_rate': 0.05,      # Step size shrinkage used in update (Learning rate)\n",
    "         'reg_alpha': 0.05,          # L1 regularization term on weights\n",
    "         'n_estimators': 700,\n",
    "         'max_depth': 3,\n",
    "         'subsample': 1,\n",
    "         'colsample_bytree': 0.90,\n",
    "         'colsample_bylevel': 0.90,\n",
    "         'silent': True,\n",
    "         'random_state': 42,\n",
    "         'objective': 'reg:linear'}\n",
    "pa_e0 = {'learning_rate': 0.05,      # Step size shrinkage used in update (Learning rate)\n",
    "         'reg_alpha': 0.1,          # L1 regularization term on weights\n",
    "         'n_estimators': 800,\n",
    "         'max_depth': 4,\n",
    "         'subsample': 1,\n",
    "         'colsample_bytree': 0.90,\n",
    "         'colsample_bylevel': 0.90,\n",
    "         'silent': True,\n",
    "         'random_state': 42,\n",
    "         'objective': 'reg:linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator pipeline\n",
    "est_bg = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=50, random_state=42)),\n",
    "    ('xgbreg', XGBRegressor(**pa_bg)),\n",
    "])\n",
    "est_e0 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=50, random_state=42)),\n",
    "    ('xgbreg', XGBRegressor(**pa_e0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=50, random_state=42,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample...     reg_alpha=0.05, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_bg.fit(X_train, y_bg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=50, random_state=42,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample...      reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_e0.fit(X_train, y_e0_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_bg = est_bg.predict(X_test)\n",
    "predicted_e0 = np.expm1(est_e0.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame({'formation_energy_ev_natom': predicted_e0,\n",
    "                          'bandgap_energy_ev': predicted_bg}) \\\n",
    "              .reset_index().rename(columns={'index': 'id'})\n",
    "predicted['id'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bandgap_energy_ev</th>\n",
       "      <th>formation_energy_ev_natom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.457427</td>\n",
       "      <td>0.192347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.926876</td>\n",
       "      <td>0.081918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.271297</td>\n",
       "      <td>0.177762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.031129</td>\n",
       "      <td>0.038247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.476494</td>\n",
       "      <td>0.145435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bandgap_energy_ev  formation_energy_ev_natom\n",
       "0   1           1.457427                   0.192347\n",
       "1   2           3.926876                   0.081918\n",
       "2   3           3.271297                   0.177762\n",
       "3   4           3.031129                   0.038247\n",
       "4   5           1.476494                   0.145435"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_e0 = rmsle(np.expm1(est_e0.predict(X_train)), np.expm1(y_e0_train))\n",
    "err_bg = rmsle(est_bg.predict(X_train), y_bg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE BG: 0.0473847146963, RMSLE E0: 0.00884794187548, RMSLE AVG: 0.0281163282859\n"
     ]
    }
   ],
   "source": [
    "# Training RMSLE values\n",
    "print \"RMSLE BG: {}, RMSLE E0: {}, RMSLE AVG: {}\".format(err_bg, err_e0,\n",
    "                                                         0.5 * (err_bg + err_e0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "predicted.to_csv(os.path.join('output', 'xgb-ext-skl-geo-pca-{}.csv'.format(now)),\n",
    "                columns=['id', 'formation_energy_ev_natom', 'bandgap_energy_ev'],\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
