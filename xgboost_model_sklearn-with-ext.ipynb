{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.14 (default, Jan 17 2018, 15:13:18) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]\n"
     ]
    }
   ],
   "source": [
    "print sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pymatgen/__init__.py:87: UserWarning: \n",
      "Pymatgen will drop Py2k support from v2019.1.1. Pls consult the documentation\n",
      "at https://www.pymatgen.org for more details.\n",
      "  at https://www.pymatgen.org for more details.\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pymatgen as mg\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'),\n",
    "                    names=['id', 'spacegroup', 'natoms', 'al',\n",
    "                           'ga', 'in', 'a', 'b', 'c',\n",
    "                           'alpha', 'beta',\n",
    "                           'gamma', 'E0',\n",
    "                           'bandgap'],\n",
    "                    header=0,\n",
    "                    sep=',')\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'),\n",
    "                    names=['id', 'spacegroup', 'natoms', 'al',\n",
    "                           'ga', 'in', 'a', 'b', 'c',\n",
    "                           'alpha', 'beta',\n",
    "                           'gamma'],\n",
    "                    header=0,\n",
    "                    sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ext = pd.read_csv(os.path.join(DATA_DIR, 'train_ext.csv'),\n",
    "                    header=0,\n",
    "                    sep=',')\n",
    "test_ext = pd.read_csv(os.path.join(DATA_DIR, 'test_ext.csv'),\n",
    "                    header=0,\n",
    "                    sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(train_ext, on='id')\n",
    "test = test.merge(test_ext, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the spacegroup_natoms category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['spacegroup_natoms'] = train['spacegroup'].astype(str) +\\\n",
    "    '_' + train['natoms'].astype(int).astype(str)\n",
    "test['spacegroup_natoms'] = test['spacegroup'].astype(str) +\\\n",
    "    '_' + test['natoms'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add cell volume and calculate atomic and mass density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cellvol'] = train.apply(lambda r: mg.Lattice.from_parameters(r['a'], r['b'], r['c'],\n",
    "                                         r['alpha'], r['beta'], r['gamma']).volume,\n",
    "                               axis=1)\n",
    "test['cellvol'] = test.apply(lambda r: mg.Lattice.from_parameters(r['a'], r['b'], r['c'],\n",
    "                                       r['alpha'], r['beta'], r['gamma']).volume,\n",
    "                             axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['atom_density'] = train['natoms'] / train['cellvol']\n",
    "test['atom_density'] = test['natoms'] / test['cellvol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['mass_density'] = train['avg_mass'] / train['cellvol']\n",
    "test['mass_density'] = test['avg_mass'] / test['cellvol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert angles to radians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['alpha_r'] = np.radians(train['alpha'])\n",
    "train['beta_r'] = np.radians(train['beta'])\n",
    "train['gamma_r'] = np.radians(train['gamma'])\n",
    "test['alpha_r'] = np.radians(test['alpha'])\n",
    "test['beta_r'] = np.radians(test['beta'])\n",
    "test['gamma_r'] = np.radians(test['gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check O fraction = 0.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['o_fraction'] = train['o_cnt'] / train['natoms']\n",
    "test['o_fraction'] = test['o_cnt'] / test['natoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (train['o_fraction'] == 0.6).all()\n",
    "assert (test['o_fraction'] == 0.6).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'natoms', 'spacegroup',\n",
    "                      'alpha', 'beta', 'gamma',\n",
    "                      'ga', 'o_cnt', 'cellvol', 'o_fraction', 'avg_mass',\n",
    "                      'bandgap', 'E0'], axis=1)\n",
    "X_test = test.drop(['id', 'natoms', 'spacegroup',\n",
    "                    'alpha', 'beta', 'gamma',\n",
    "                    'ga', 'o_cnt', 'cellvol', 'o_fraction', 'avg_mass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use log1p of energies to correct for skew\n",
    "y_bg_train = train['bandgap']\n",
    "y_e0_train = np.log1p(train['E0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode spacegroup_natoms\n",
    "X_train = pd.concat([X_train.drop('spacegroup_natoms', axis=1),\n",
    "                    pd.get_dummies(X_train['spacegroup_natoms'])], axis=1)\n",
    "X_test = pd.concat([X_test.drop('spacegroup_natoms', axis=1),\n",
    "                    pd.get_dummies(X_test['spacegroup_natoms'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Sklearn Model with XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.10,      # Step size shrinkage used in update (Learning rate)\n",
    "         'reg_alpha': 0.01,          # L1 regularization term on weights\n",
    "         'n_estimators': 60,\n",
    "         'max_depth': 5,\n",
    "         'subsample': 1,\n",
    "         'colsample_bytree': 0.90,\n",
    "         'colsample_bylevel': 0.90,\n",
    "         'silent': True,\n",
    "         'random_state': 42,\n",
    "         'objective': 'reg:linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator pipeline\n",
    "est = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgbreg', XGBRegressor(**param)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=60,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=42,\n",
       "       reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search for bandgap model\n",
    "t_md = [3, 4, 5, 6, 7]\n",
    "t_lr = [0.01, 0.02, 0.05, 0.10, 0.20, 0.3]\n",
    "t_ne = range(50, 500, 50)\n",
    "gridsearch_bg_0 = GridSearchCV(est,\n",
    "                              {'xgbreg__max_depth': t_md,\n",
    "                               'xgbreg__learning_rate': t_lr,\n",
    "                               'xgbreg__n_estimators': t_ne,\n",
    "                              },\n",
    "                              cv=5,\n",
    "                              n_jobs=4,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              return_train_score=False,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done 211 tasks      | elapsed:   52.6s\n",
      "[Parallel(n_jobs=4)]: Done 461 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 811 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 1261 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=4)]: Done 1350 out of 1350 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_...    reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'xgbreg__n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 450], 'xgbreg__max_depth': [3, 4, 5, 6, 7], 'xgbreg__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_bg_0.fit(X_train, y_bg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbreg__learning_rate': 0.05,\n",
       " 'xgbreg__max_depth': 3,\n",
       " 'xgbreg__n_estimators': 250}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_bg_0.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047868832486723044"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridsearch_bg_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best regularization\n",
    "t_ra = [0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "gridsearch_bg_1 = GridSearchCV(est,\n",
    "                              {'xgbreg__reg_alpha': t_ra,\n",
    "                              },\n",
    "                              cv=5,\n",
    "                              n_jobs=4,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              return_train_score=False,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  25 out of  25 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_...    reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'xgbreg__reg_alpha': [0.1, 0.05, 0.01, 0.005, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_bg_1.fit(X_train, y_bg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbreg__reg_alpha': 0.01}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_bg_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05032338635026175"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridsearch_bg_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search for formation energy model\n",
    "t_md = [3, 4, 5, 6, 7]\n",
    "t_lr = [0.01, 0.02, 0.05, 0.10, 0.20, 0.3]\n",
    "t_ne = range(50, 500, 50)\n",
    "gridsearch_e0_0 = GridSearchCV(est,\n",
    "                              {'xgbreg__max_depth': t_md,\n",
    "                               'xgbreg__learning_rate': t_lr,\n",
    "                               'xgbreg__n_estimators': t_ne,\n",
    "                              },\n",
    "                              cv=5,\n",
    "                              n_jobs=4,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              return_train_score=False,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done 211 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=4)]: Done 461 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 811 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=4)]: Done 1261 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=4)]: Done 1350 out of 1350 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_...    reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'xgbreg__n_estimators': [50, 100, 150, 200, 250, 300, 350, 400, 450], 'xgbreg__max_depth': [3, 4, 5, 6, 7], 'xgbreg__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_e0_0.fit(X_train, y_e0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbreg__learning_rate': 0.05,\n",
       " 'xgbreg__max_depth': 4,\n",
       " 'xgbreg__n_estimators': 150}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_e0_0.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011021747873143457"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridsearch_e0_0.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best regularization\n",
    "t_ra = [0.2, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "gridsearch_e0_1 = GridSearchCV(est,\n",
    "                              {'xgbreg__reg_alpha': t_ra,\n",
    "                              },\n",
    "                              cv=5,\n",
    "                              n_jobs=4,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              return_train_score=False,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_...    reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'xgbreg__reg_alpha': [0.2, 0.1, 0.05, 0.01, 0.005, 0.001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_e0_1.fit(X_train, y_e0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbreg__reg_alpha': 0.1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_e0_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001104495414100288"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-gridsearch_e0_1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models using optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_bg = {'learning_rate': 0.05,      # Step size shrinkage used in update (Learning rate)\n",
    "         'reg_alpha': 0.01,          # L1 regularization term on weights\n",
    "         'n_estimators': 250,\n",
    "         'max_depth': 3,\n",
    "         'subsample': 1,\n",
    "         'colsample_bytree': 0.90,\n",
    "         'colsample_bylevel': 0.90,\n",
    "         'silent': True,\n",
    "         'random_state': 42,\n",
    "         'objective': 'reg:linear'}\n",
    "pa_e0 = {'learning_rate': 0.05,      # Step size shrinkage used in update (Learning rate)\n",
    "         'reg_alpha': 0.10,          # L1 regularization term on weights\n",
    "         'n_estimators': 150,\n",
    "         'max_depth': 4,\n",
    "         'subsample': 1,\n",
    "         'colsample_bytree': 0.90,\n",
    "         'colsample_bylevel': 0.90,\n",
    "         'silent': True,\n",
    "         'random_state': 42,\n",
    "         'objective': 'reg:linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator pipeline\n",
    "est_bg = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgbreg', XGBRegressor(**pa_bg)),\n",
    "])\n",
    "est_e0 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgbreg', XGBRegressor(**pa_e0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=250,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=42,\n",
       "       reg_alpha=0.01, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_bg.fit(X_train, y_bg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('xgbreg', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=150,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=42,\n",
       "       reg_alpha=0.1, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_e0.fit(X_train, y_e0_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_bg = est_bg.predict(X_test)\n",
    "predicted_e0 = np.expm1(est_e0.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame({'formation_energy_ev_natom': predicted_e0,\n",
    "                          'bandgap_energy_ev': predicted_bg}) \\\n",
    "              .reset_index().rename(columns={'index': 'id'})\n",
    "predicted['id'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bandgap_energy_ev</th>\n",
       "      <th>formation_energy_ev_natom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.555830</td>\n",
       "      <td>0.194493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.653345</td>\n",
       "      <td>0.062524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.428888</td>\n",
       "      <td>0.163906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.070188</td>\n",
       "      <td>0.030007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.563939</td>\n",
       "      <td>0.140292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bandgap_energy_ev  formation_energy_ev_natom\n",
       "0   1           1.555830                   0.194493\n",
       "1   2           3.653345                   0.062524\n",
       "2   3           3.428888                   0.163906\n",
       "3   4           3.070188                   0.030007\n",
       "4   5           1.563939                   0.140292"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_e0 = rmsle(np.expm1(est_e0.predict(X_train)), np.expm1(y_e0_train))\n",
    "err_bg = rmsle(est_bg.predict(X_train), y_bg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE BG: 0.0728351173101, RMSLE E0: 0.027578048241, RMSLE AVG: 0.0502065827755\n"
     ]
    }
   ],
   "source": [
    "# Training RMSLE values\n",
    "print \"RMSLE BG: {}, RMSLE E0: {}, RMSLE AVG: {}\".format(err_bg, err_e0,\n",
    "                                                         0.5 * (err_bg + err_e0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "predicted.to_csv(os.path.join('output', 'xgb-ext-skl-{}.csv'.format(now)),\n",
    "                columns=['id', 'formation_energy_ev_natom', 'bandgap_energy_ev'],\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
